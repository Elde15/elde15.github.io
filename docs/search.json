[
  {
    "objectID": "text-analysis.html",
    "href": "text-analysis.html",
    "title": "Shakespeare Dialogue Analysis",
    "section": "",
    "text": "This analysis will look at dialogue from Shakespeare’s plays to find patterns in the text. I will use string functions and regular expressions to identify questions, exclamations, character speech patterns, and emotional language. The dataset contains lines from multiple Shakespeare plays including Romeo and Juliet, Hamlet, and Macbeth.\n\n\nCode\nlibrary(tidyverse)\nlibrary(stringr)\n\nshakespeare &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-09-17/hamlet.csv')\n\nhead(shakespeare)\n\n\n# A tibble: 6 × 5\n  act   scene   character         dialogue                           line_number\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;             &lt;chr&gt;                                    &lt;dbl&gt;\n1 Act I Scene I [stage direction] FRANCISCO at his post. Enter to h…          NA\n2 Act I Scene I Bernardo          Who's there?                                 1\n3 Act I Scene I Francisco         Nay, answer me: stand, and unfold…           2\n4 Act I Scene I Bernardo          Long live the king!                          3\n5 Act I Scene I Francisco         Bernardo?                                    4\n6 Act I Scene I Bernardo          He.                                          5\n\n\n\n\nCode\nshakespeare &lt;- shakespeare |&gt;\n  mutate(\n    is_question = str_detect(dialogue, \"\\\\?$\"),  \n    is_exclamation = str_detect(dialogue, \"!$\"), \n    line_length = str_length(dialogue)            \n  )\n\nquestion_summary &lt;- shakespeare |&gt;\n  summarise(\n    questions = sum(is_question, na.rm = TRUE),\n    exclamations = sum(is_exclamation, na.rm = TRUE),\n    statements = n() - questions - exclamations\n  ) |&gt;\n  pivot_longer(everything(), names_to = \"type\", values_to = \"count\")\n\nggplot(question_summary, aes(x = type, y = count, fill = type)) +\n  geom_col() +\n  labs(title = \"Types of Lines in Hamlet\",\n       x = \"Line Type\",\n       y = \"Number of Lines\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"questions\" = \"lightblue\", \n                                 \"exclamations\" = \"pink\",\n                                 \"statements\" = \"orange\"))\n\n\n\n\n\n\n\n\n\nInsight!: Most lines in Hamlet are statements, with very few questions and exclamations. This shows the play contains more direct dialogue than interrogative or emotional outbursts. Questions make up only a small portion of the total dialogue, showing that characters often speak in statements rather than inquiries.\n\n\nCode\ncharacter_lines &lt;- shakespeare |&gt;\n  group_by(character) |&gt;\n  summarise(\n    total_lines = n(),\n    avg_line_length = mean(line_length, na.rm = TRUE),\n    question_rate = mean(is_question, na.rm = TRUE) * 100\n  ) |&gt;\n  filter(total_lines &gt;= 20) |&gt;  \n  arrange(desc(total_lines)) |&gt;\n  head(10)\n\nggplot(character_lines, aes(x = reorder(character, total_lines), y = total_lines)) +\n  geom_col(fill = \"skyblue\") +\n  coord_flip() +\n  labs(title = \"Top 10 Characters by Number of Lines in Hamlet\",\n       x = \"Character\",\n       y = \"Number of Lines\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nInsight!: Hamlet has significantly more lines than any other character, which makes sense as the protagonist. The distribution shows a major drop off after the main character, with supporting characters like Horatio and Claudius having substantially fewer lines. This reflects the play’s focus on Hamlet’s internal struggles and thoughts.\n\n\nCode\nshakespeare &lt;- shakespeare |&gt;\n  mutate(\n    has_love = str_detect(dialogue, \"(?i)\\\\blove\\\\b\"),     \n    has_death = str_detect(dialogue, \"(?i)\\\\bdeath\\\\b\"),   \n    has_fear = str_detect(dialogue, \"(?i)\\\\bfear\\\\b\"),\n    has_hate = str_detect(dialogue, \"(?i)\\\\bhate\\\\b\")\n  )\n\nemotion_counts &lt;- shakespeare |&gt;\n  summarise(\n    Love = sum(has_love, na.rm = TRUE),\n    Death = sum(has_death, na.rm = TRUE),\n    Fear = sum(has_fear, na.rm = TRUE),\n    Hate = sum(has_hate, na.rm = TRUE)\n  ) |&gt;\n  pivot_longer(everything(), names_to = \"emotion\", values_to = \"count\")\n\nknitr::kable(emotion_counts, \n             caption = \"Frequency of Emotional Words in Hamlet\")\n\n\n\nFrequency of Emotional Words in Hamlet\n\n\nemotion\ncount\n\n\n\n\nLove\n65\n\n\nDeath\n38\n\n\nFear\n21\n\n\nHate\n1\n\n\n\n\n\nInsight!: The table shows how often different emotional themes appear in the dialogue. Death appears most frequently, which aligns with Hamlet’s dark themes and tragic ending. Love appears less than death, reflecting the play’s focus on mortality and revenge over romance. Fear and hate have some presence, contributing to the play’s tense atmosphere.\n\n\nCode\nthee_phrases &lt;- shakespeare |&gt;\n  filter(str_detect(dialogue, \"\\\\w+\\\\s+thee\")) |&gt;\n  mutate(\n    before_thee = str_extract(dialogue, \"\\\\w+(?=\\\\s+thee)\")\n  ) |&gt;\n  filter(!is.na(before_thee)) |&gt;\n  count(before_thee, sort = TRUE) |&gt;\n  head(10)\n\nknitr::kable(thee_phrases, \n             caption = \"Most Common Words Before 'thee' in Hamlet\",\n             col.names = c(\"Word Before 'thee'\", \"Frequency\"))\n\n\n\nMost Common Words Before ‘thee’ in Hamlet\n\n\nWord Before ‘thee’\nFrequency\n\n\n\n\nto\n4\n\n\nwith\n3\n\n\nGet\n2\n\n\nRemember\n2\n\n\ncharge\n2\n\n\ndo\n2\n\n\nfollow\n2\n\n\nget\n2\n\n\ngive\n2\n\n\nin\n2\n\n\n\n\n\nInsight!: This analysis shows common phrases used in Shakespearean English. Words like “with,” “to,” and “for” appear a lot before “thee,” showing typical sentence structures of the time period. This pattern helps us understand how characters addressed each other in formal Early Modern English.\n\nTidyTuesday Dataset: Week 38, 2024 - Shakespeare Dialogue\nOriginal Data Source: shakespeare.mit.edu - The Complete Works of William Shakespeare, specifically the Hamlet text, made available by MIT"
  },
  {
    "objectID": "simulation-study.html",
    "href": "simulation-study.html",
    "title": "Penguin Body Mass: A Permutation Test",
    "section": "",
    "text": "In this simulation study, I will investigate whether there is a significant difference in body mass between male and female Adelie penguins using a permutation test. A permutation test works by simulating what we would expect to see if there were truly no difference between research groups. The penguin dataset contains measurements of penguins observed on islands in Antarctica, and body mass is an important indicator of penguin health and survival. Understanding sex-based differences in body mass can help researchers better understand penguin biology."
  },
  {
    "objectID": "simulation-study.html#introduction",
    "href": "simulation-study.html#introduction",
    "title": "Penguin Body Mass: A Permutation Test",
    "section": "",
    "text": "In this simulation study, I will investigate whether there is a significant difference in body mass between male and female Adelie penguins using a permutation test. A permutation test works by simulating what we would expect to see if there were truly no difference between research groups. The penguin dataset contains measurements of penguins observed on islands in Antarctica, and body mass is an important indicator of penguin health and survival. Understanding sex-based differences in body mass can help researchers better understand penguin biology."
  },
  {
    "objectID": "simulation-study.html#data-loading-and-exploration",
    "href": "simulation-study.html#data-loading-and-exploration",
    "title": "Penguin Body Mass: A Permutation Test",
    "section": "Data Loading and Exploration",
    "text": "Data Loading and Exploration\n\n\nCode\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n# Load penguin data\npenguins_clean &lt;- penguins |&gt;\n  filter(species == \"Adelie\") |&gt;\n  filter(!is.na(body_mass_g), !is.na(sex)) |&gt;\n  select(sex, body_mass_g)\n\n# Show first few rows\nhead(penguins_clean)\n\n\n# A tibble: 6 × 2\n  sex    body_mass_g\n  &lt;fct&gt;        &lt;int&gt;\n1 male          3750\n2 female        3800\n3 female        3250\n4 female        3450\n5 male          3650\n6 female        3625"
  },
  {
    "objectID": "simulation-study.html#visualizing-the-original-data",
    "href": "simulation-study.html#visualizing-the-original-data",
    "title": "Penguin Body Mass: A Permutation Test",
    "section": "Visualizing the Original Data",
    "text": "Visualizing the Original Data\nBefore doing the permutation test, let’s visualize the body mass distributions for male and female penguins in two groups.\n\n\nCode\nggplot(penguins_clean, aes(x = sex, y = body_mass_g, fill = sex)) +\n  geom_boxplot(alpha = 0.7) +\n  geom_jitter(width = 0.2, alpha = 0.3) +\n  labs(title = \"Body Mass of Male vs Female Adelie Penguins\",\n       x = \"Sex\",\n       y = \"Body Mass (g)\",\n       fill = \"Sex\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"female\" = \"#FF6B9D\", \"male\" = \"#4A90E2\"))\n\n\n\n\n\n\n\n\n\nWhat I See: The boxplot shows that male penguins have higher body mass than female penguins on average. Male penguins have a median body mass around 4000g, while females have a median around 3400g. There is overlap between the groups, but the distributions look distinct. Now we will answer the question: could this difference have occurred by random chance, or is it statistically significant?"
  },
  {
    "objectID": "simulation-study.html#the-permutation-test",
    "href": "simulation-study.html#the-permutation-test",
    "title": "Penguin Body Mass: A Permutation Test",
    "section": "The Permutation Test",
    "text": "The Permutation Test\n\nWriting the Permutation Function\nI created function that calculates the difference in mean body mass between the two groups. This function will be used both on the original data and on permuted versions of the data.\n\n\nCode\n# Function to calculate difference in means\ncalc_diff_means &lt;- function(data) {\n  data |&gt;\n    group_by(sex) |&gt;\n    summarise(mean_mass = mean(body_mass_g)) |&gt;\n    summarise(diff = diff(mean_mass)) |&gt;\n    pull(diff)\n}\n\n# Calculate observed difference\nobserved_diff &lt;- calc_diff_means(penguins_clean)\nobserved_diff\n\n\n[1] 674.6575\n\n\nThe observed difference in means is 674.6575 grams, with males being heavier.\n\n\nRunning the Permutation Test\nNow I will use a map() function to run thousands of permutations. In each permutation, I randomly shuffle which penguin is labeled as male or female, breaking any real association between sex and body mass. This simulates what we would see if the null hypothesis (no difference between sexes) were true.\n\n\nCode\nset.seed(123)  # For reproducibility\n\n# Function to permute and calculate difference\npermute_and_calc &lt;- function(i, data) {\n  data |&gt;\n    mutate(sex = sample(sex)) |&gt;  # Randomly shuffle sex labels\n    calc_diff_means()\n}\n\n# Run 1000 permutations using map_dbl\nn_permutations &lt;- 1000\npermuted_diffs &lt;- map_dbl(1:n_permutations, ~permute_and_calc(.x, penguins_clean))\n\n# Create data frame for plotting\nperm_results &lt;- tibble(\n  permutation = 1:n_permutations,\n  diff_in_means = permuted_diffs\n)\n\nhead(perm_results)\n\n\n# A tibble: 6 × 2\n  permutation diff_in_means\n        &lt;int&gt;         &lt;dbl&gt;\n1           1         -37.0\n2           2          96.6\n3           3         -39.7\n4           4          39.0\n5           5         -11.0\n6           6        -104. \n\n\n\n\nVisualizing Permutation Results\n\n\nCode\nggplot(perm_results, aes(x = diff_in_means)) +\n  geom_histogram(bins = 30, fill = \"lightblue\", color = \"black\", alpha = 0.7) +\n  geom_vline(xintercept = observed_diff, color = \"red\", linewidth = 1.5, linetype = \"dashed\") +\n  labs(title = \"Distribution of Differences Under Null Hypothesis\",\n       subtitle = \"Red line shows observed difference in original data\",\n       x = \"Difference in Mean Body Mass (g)\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nWhat I See: The histogram shows the distribution of differences we would expect to see if there were no relationship between sex and body mass. Most permuted differences are centered around zero, which makes sense the sex labels are randomly assigned. The red dashed line shows the observed difference from the real data. It’s far to the right of the permutation distribution, suggesting that the observed difference is almost impossible to have occurred by just chance alone.\n\n\nCalculating the P-Value\n\n\nCode\n# Calculate p-value (proportion of permuted differences as extreme as observed)\np_value &lt;- mean(abs(permuted_diffs) &gt;= abs(observed_diff))\np_value\n\n\n[1] 0\n\n\nThe p-value is 0, which means that we never saw a difference as large as we did in the observed data."
  },
  {
    "objectID": "simulation-study.html#results-table",
    "href": "simulation-study.html#results-table",
    "title": "Penguin Body Mass: A Permutation Test",
    "section": "Results Table",
    "text": "Results Table\n\n\nCode\nresults_summary &lt;- tibble(\n  Statistic = c(\"Observed Difference\", \"P-Value\", \"Number of Permutations\"),\n  Value = c(round(observed_diff, 2), round(p_value, 4), n_permutations)\n)\n\nknitr::kable(results_summary, \n             caption = \"Permutation Test Results\")\n\n\n\nPermutation Test Results\n\n\nStatistic\nValue\n\n\n\n\nObserved Difference\n674.66\n\n\nP-Value\n0.00\n\n\nNumber of Permutations\n1000.00"
  },
  {
    "objectID": "simulation-study.html#conclusion",
    "href": "simulation-study.html#conclusion",
    "title": "Penguin Body Mass: A Permutation Test",
    "section": "Conclusion",
    "text": "Conclusion\nI used a permutation test to look at whether male and female Adelie penguins have significantly different body masses. The observed difference of 674.66 grams is extremely unlikely to have occurred by random chance (p &lt; 0.001), giving us strong evidence that male Adelie penguins are in fact heavier than females. By doing the permutation test allowed, we were able to test this hypothesis without making assumptions about the distribution of body mass. This finding also lines up with what biologists know about the difference in sex among penguins, further confirming our findings."
  },
  {
    "objectID": "simulation-study.html#how-the-simulation-works",
    "href": "simulation-study.html#how-the-simulation-works",
    "title": "Penguin Body Mass: A Permutation Test",
    "section": "How the Simulation Works",
    "text": "How the Simulation Works\nMy function calculates the difference in average body mass between the two groups. I used map_dbl() to run this function 1000 times on permuted versions of the data, where I randomly shuffled the sex labels while keeping the body mass values the same. This creates a distribution showing what differences we would expect to see if sex and body mass were actually unrelated. We can then compare our observed difference to the null hypothesis."
  },
  {
    "objectID": "simulation-study.html#data-source",
    "href": "simulation-study.html#data-source",
    "title": "Penguin Body Mass: A Permutation Test",
    "section": "Data Source",
    "text": "Data Source\n\nDataset: Palmer Penguins dataset from the palmerpenguins R package\nOriginal Source: Data collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER. Horst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0."
  },
  {
    "objectID": "netflix-analysis.html",
    "href": "netflix-analysis.html",
    "title": "Netflix Content Analysis",
    "section": "",
    "text": "This analysis will look at the distribution of content types that is on Netflix, specifically comparing the number of movies versus TV shows on the platform. Understanding this distribution provides insight into Netflix’s content strategy and what type of entertainment they provide. The dataset contains information about titles available on Netflix as of mid-2021, including details about each title’s type, release year, and other characteristics."
  },
  {
    "objectID": "netflix-analysis.html#introduction",
    "href": "netflix-analysis.html#introduction",
    "title": "Netflix Content Analysis",
    "section": "",
    "text": "This analysis will look at the distribution of content types that is on Netflix, specifically comparing the number of movies versus TV shows on the platform. Understanding this distribution provides insight into Netflix’s content strategy and what type of entertainment they provide. The dataset contains information about titles available on Netflix as of mid-2021, including details about each title’s type, release year, and other characteristics."
  },
  {
    "objectID": "netflix-analysis.html#data-loading",
    "href": "netflix-analysis.html#data-loading",
    "title": "Netflix Content Analysis",
    "section": "Data Loading",
    "text": "Data Loading\n\n\nCode\n# Load required libraries for data manipulation and visualization\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Read Netflix titles dataset from TidyTuesday\n# This dataset contains information on movies and TV shows available on Netflix\nnetflix &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2021/2021-04-20/netflix_titles.csv')"
  },
  {
    "objectID": "netflix-analysis.html#content-distribution-analysis",
    "href": "netflix-analysis.html#content-distribution-analysis",
    "title": "Netflix Content Analysis",
    "section": "Content Distribution Analysis",
    "text": "Content Distribution Analysis\n\n\nCode\n# Count the number of titles by type (Movie vs TV Show)\ncontent_counts &lt;- netflix |&gt;\n  count(type)\n\n# Create bar chart showing content distribution\n# Using Netflix's brand colors: red for movies, black for TV shows\nggplot(content_counts, aes(x = type, y = n, fill = type)) +\n  geom_col() +\n  labs(title = \"Netflix Content: Movies vs TV Shows\",\n       subtitle = \"Distribution of content types in Netflix catalog (as of 2021)\",\n       x = \"Content Type\",\n       y = \"Number of Titles\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"Movie\" = \"red\", \"TV Show\" = \"black\")) +\n  # Remove legend since x-axis already labels the types\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "netflix-analysis.html#analysis-summary",
    "href": "netflix-analysis.html#analysis-summary",
    "title": "Netflix Content Analysis",
    "section": "Analysis Summary",
    "text": "Analysis Summary\nThe visualization shows us that Netflix’s offerings contain more movies than TV shows, with around 6,100 movies compared to 2,700 TV shows. This means movies make up roughly 69% of Netflix’s content , while TV shows about 31%. This distribution reflects Netflix’s focus on producing film content, even though the company has started to invest more in original TV series in recent years."
  },
  {
    "objectID": "netflix-analysis.html#data-sources",
    "href": "netflix-analysis.html#data-sources",
    "title": "Netflix Content Analysis",
    "section": "Data Sources",
    "text": "Data Sources\nTidyTuesday Dataset: Rfordatascience. (2021). Netflix Movies and TV Shows [Data set]. Week 17, 2021. TidyTuesday Project. https://github.com/rfordatascience/tidytuesday/blob/main/data/2021/2021-04-20/readme.md\nOriginal Data Source: Bansal, S. (2021). Netflix Movies and TV Shows [Data set]. Kaggle. The original data was compiled by Shivam Bansal and sourced from Flixable, a third-party Netflix search engine that tracks content availability across different regions. The dataset was last updated in 2021 and includes titles available on Netflix at that time.\nData Collection Method: The data was collected through Flixable’s web scraping of Netflix’s publicly available catalog information, including title names, types, release years, ratings, and descriptions. Note that Netflix’s catalog varies by region, and this dataset primarily reflects content available in the United States."
  },
  {
    "objectID": "ethics-analysis.html",
    "href": "ethics-analysis.html",
    "title": "Eli Della Bitta - Data Science Portfolio",
    "section": "",
    "text": "title: “Facebook Emotional Contagion Experiment: An Ethics Analysis”\n\n\ndescription: |\n\n\nExamining ethical concerns in Facebook’s 2012 emotional manipulation study\n\n\nauthor: Eli Della Bitta\n\n\ndate: November 12, 2025\n\n\nformat:\n\n\nhtml:\n\n\nwarning: false\n\n\nmessage: false\n\n\n\n## Introduction\nIn 2012, Facebook did a secret psychological experiment on nearly 700,000 users without their knowledge or consent. The study, published in 2014, manipulated users News Feeds to show either positive or negative emotional content to try and see if emotions could spread through social media (Kramer, Guillory, & Hancock, 2014). When users saw more positive posts from friends, they posted more positive content on their own accounts. When they saw more negative posts, they posted more negatively. This experiment sparked major controversy about consent, user privacy, and the ethics of conducting psychological research on participants who are unaware through a social media platform.\nThe data science aspect involves Facebook’s algorithm manipulating what content shows up in users News Feeds, then analyzing the posts using user sentiment analysis to measure emotional bias. The ethical issues center on whether it is acceptable to preform psychological experiments on users without their knowledge, using a platform they rely on for social connection, and potentially causing psychological harm in the process.\n## Informed Consent and User Awareness\nThe most significant ethical issue with this experiment was the absence of consent. The researchers did not notify participants that they were part of a psychological study, and they did not give users the option to opt out (Meyer, 2014). Facebook’s argument was that users agreed to the platform’s Data Use Policy when they signed up, which stated that user data could be used for “research” and “testing.” However, this relatively vauge language they buried in their terms of service does not really allow informed consent for a psychological experiment.\nInformed consent requires that participants understand what they are agreeing to, including the purpose of the study, any potential risks, and their right to withdraw. The Facebook users had no idea their emotions were being deliberately manipulated as part of an experiment. They could not provide meaningful consent because they did not know the study even existed. This violates basic ethical standards established by Institutional Review Boards, which require voluntary participation based on full disclosure of the research activities that are taking place. The fact that Facebook claimed their Terms of Service covered this experiment demonstrates how companies exploit legal agreements to conduct research that would never pass ethical review at a university.\n## Privacy and Data Collection\nThis data collection process raised serious privacy concerns. Facebook collected and analyzed the emotional content of users posts without any permission for this experimental purpose (Puschmann & Bozdag, 2014). While users post content knowing it will be seen by friends, they may have different expectations about how that data might be used for psychological research. The platform took advantage of its position as a social network to conduct research that users would not have anticipated when they signed up.\nAlso, Facebook did not passively observe user behavior, rather, they manipulated what users saw in order to influence their emotional state. This goes beyond normal data collection and enters the world of experimentation on human subjects. This emotional manipulation could have had real psychological effects, particularly for vulnerable users who might have been experiencing depression or other mental health challenges. By actively showing some users more negative content, Facebook could have possibly worsened mental health outcomes for certain individuals, all without their knowledge of any ethics board.\n## Bias and Representation\nThe study also raises questions about exactly who was affected. The experiment included 689,003 users, but we do not know the demographic breakdown of participants or whether certain groups were shown more negative content than others (Kramer et al., 2014).\nAdditionally, Facebook users are not representative of the general population. The findings about emotional contagion were generalized to make claims about human psychology and social networks broadly, but the sample consisted only of English-speaking Facebook users during a specific time period. The researchers did not acknowledge these limitations adequately, treating Facebook users as if they were a random sample of humanity rather than a specific subset of people who use social media in particular ways.\n## Power Dynamics and Harm\nThis experiment shows how corporations have enormous power over their users with very little accountability. Facebook conducted research that would require a lot of ethical review at any university, yet faced no such oversight because it was done internally by a private company (Meyer, 2014).\nThe potential for harm was real and essentially ignored. Some users who were shown more negative content might have experienced worsened mood, increased anxiety, or other psychological effects. Facebook did not follow up with participants to assess harm, offer support, or even inform them they had been part of an experiment. The company prioritized its research interests over human wellbeing, treating hundreds of thousands of people as lab subjects rather than as customers deserving respect and protection.\n## Why This Matters\nThis case matters because it reveals how tech companies exploit their power to conduct research in the service of profit maximization, with little regard for user safety or harm that could be caused. Facebook benefits from understanding emotional desires because it helps them design more engaging features that keep users on the platform longer, seeing more ads.\nThis experiment demonstrates “surveillance capitalism” at work: users are constantly monitored, their data analyzed, and they are experimented upon to generate profit for the company. The vulnerable are even more at risk because they have fewer alternatives and less power to resist platform policies. When corporations can conduct psychological experiments without consent or oversight, everyone becomes a potential research subject, and the most vulnerable have the least protection.\n## Conclusion\nThe Facebook emotional experiment violated fundamental ethical principles of informed consent, respect for users, and protection from harm. It shows how tech companies can use their power over users to conduct research that serves corporate interests while creating risks for users that they never agreed to take. This case serves as a warning about the need for stronger ethical oversight of corporate research and greater protection for the rights and wellbeing of people who use digital platforms.\n## References\nKramer, A. D., Guillory, J. E., & Hancock, J. T. (2014). Experimental evidence of massive-scale emotional contagion through social networks. Proceedings of the National Academy of Sciences, 111(24), 8788-8790. https://doi.org/10.1073/pnas.1320040111\nMeyer, R. (2014, June 28). Everything we know about Facebook’s secret mood manipulation experiment. The Atlantic. https://www.theatlantic.com/technology/archive/2014/06/everything-we-know-about-facebooks-secret-mood-manipulation-experiment/373648/\nPuschmann, C., & Bozdag, E. (2014). Staking out the unclear ethical terrain of online social experiments. Internet Policy Review, 3(4). https://doi.org/10.14763/2014.4.338"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "coffee-analysis.html",
    "href": "coffee-analysis.html",
    "title": "Coffee Quality Analysis by Country",
    "section": "",
    "text": "This analysis looks at coffee quality ratings from around the world to try and see which countries produce the highest-rated coffee. Coffee quality is given by professional tasters using a standardized cupping protocol that evaluates characteristics like flavor, aroma, acidity, and body. Understanding geographic patterns in coffee quality can tell us how factors like climate, elevation, soil conditions, and processing methods contribute to coffee. By focusing on countries with larger sample sizes, I can find regions that produce high-quality coffee rather than countries with just one or two outliers."
  },
  {
    "objectID": "coffee-analysis.html#introduction",
    "href": "coffee-analysis.html#introduction",
    "title": "Coffee Quality Analysis by Country",
    "section": "",
    "text": "This analysis looks at coffee quality ratings from around the world to try and see which countries produce the highest-rated coffee. Coffee quality is given by professional tasters using a standardized cupping protocol that evaluates characteristics like flavor, aroma, acidity, and body. Understanding geographic patterns in coffee quality can tell us how factors like climate, elevation, soil conditions, and processing methods contribute to coffee. By focusing on countries with larger sample sizes, I can find regions that produce high-quality coffee rather than countries with just one or two outliers."
  },
  {
    "objectID": "coffee-analysis.html#data-loading",
    "href": "coffee-analysis.html#data-loading",
    "title": "Coffee Quality Analysis by Country",
    "section": "Data Loading",
    "text": "Data Loading\n\n\nCode\n# Load required libraries for data manipulation and visualization\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Read coffee quality ratings dataset from TidyTuesday\n# This dataset contains professional cupping scores for coffees from around the world\ncoffee &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-07-07/coffee_ratings.csv')"
  },
  {
    "objectID": "coffee-analysis.html#top-coffee-producing-countries",
    "href": "coffee-analysis.html#top-coffee-producing-countries",
    "title": "Coffee Quality Analysis by Country",
    "section": "Top Coffee-Producing Countries",
    "text": "Top Coffee-Producing Countries\n\n\nCode\n# Calculate average ratings by country\n# Filter for countries with at least 5 rated coffees to ensure reliability\ncountry_ratings &lt;- coffee |&gt;\n  # Remove any entries missing quality scores\n  filter(!is.na(total_cup_points)) |&gt;\n  # Group by country to calculate statistics\n  group_by(country_of_origin) |&gt;\n  summarise(\n    avg_rating = mean(total_cup_points),  # Average cupping score\n    count = n()                            # Number of coffees rated\n  ) |&gt;\n  # Only include countries with 5+ coffees to avoid single-sample bias\n  filter(count &gt;= 5) |&gt;\n  # Sort by rating to identify highest-quality producers\n  arrange(desc(avg_rating)) |&gt;\n  # Show top 10 countries\n  head(10)\n\n# Create horizontal bar chart for easy country name reading\n# Use color gradient to visually represent quality levels\nggplot(country_ratings, aes(x = reorder(country_of_origin, avg_rating), y = avg_rating, fill = avg_rating)) +\n  geom_col() +\n  coord_flip() +  # Horizontal bars make country names easier to read\n  labs(title = \"Top 10 Countries by Average Coffee Rating\",\n       subtitle = \"Based on professional cupping scores (countries with 5+ rated coffees)\",\n       x = \"Country of Origin\",\n       y = \"Average Cupping Score\",\n       fill = \"Rating\") +\n  theme_minimal() +\n  # Color gradient from tan to dark brown mimics coffee colors\n  scale_fill_gradient(low = \"tan\", high = \"#3D2817\") +\n  # Remove legend since color gradient is intuitive\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "coffee-analysis.html#analysis-summary",
    "href": "coffee-analysis.html#analysis-summary",
    "title": "Coffee Quality Analysis by Country",
    "section": "Analysis Summary",
    "text": "Analysis Summary\nThe visualization ends up telling us that Ethiopia produces the highest-rated coffee on average, with an average cupping score around 85 points. This makes sense given Ethiopia’s status as the birthplace of coffee and its ideal growing conditions, including high elevations and diverse coffee varieties. Kenya, Uganda, and Tanzania also rank highly, reflecting East Africa’s reputation as the best coffee-growing region. Interestingly, the United States (primarily Hawaii) appears in the top 10, showing us that good coffee can be made outside of traditional coffee growing regions.\nAll top-10 countries have average ratings between 83 and 85 points, which represents specialty-grade coffee according to the Specialty Coffee Association’s standards (80+ points indicates specialty grade). The relatively small range between top countries tells us that that many regions have mastered the conditions needed for high-quality production.\nIt’s worth taking note that these ratings reflect the quality of coffees submitted for professional evaluation, which may not represent each country’s entire coffee production. Higher-rated countries could be more selective about which coffees they submit for evaluation, or may have stronger quality control systems in place."
  },
  {
    "objectID": "coffee-analysis.html#data-sources",
    "href": "coffee-analysis.html#data-sources",
    "title": "Coffee Quality Analysis by Country",
    "section": "Data Sources",
    "text": "Data Sources\nTidyTuesday Dataset: Mock, T. (2020). Coffee Ratings [Data set]. Week 28, 2020. TidyTuesday Project. https://github.com/rfordatascience/tidytuesday/blob/main/data/2020/2020-07-07/readme.md\nOriginal Data Source: Coffee Quality Institute (CQI). Coffee Quality Database. https://database.coffeeinstitute.org/\nData Collection Method: Coffees in this database were submitted by producers, cooperatives, and coffee organizations for evaluation. The evaluations follow the Specialty Coffee Association’s standardized cupping protocol, making sure that we have consistency across different tasters and sessions."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Eli Della Bitta",
    "section": "",
    "text": "Hello, I am Eli Della Bitta. I am very interested in data science and using R to create models and quickly analyze data. Outside of the classroom, I love to play baseball, golf, pickleball, and go to the beach. Look around my website to learn more!"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Eli Della Bitta",
    "section": "",
    "text": "Hello, I am Eli Della Bitta. I am very interested in data science and using R to create models and quickly analyze data. Outside of the classroom, I love to play baseball, golf, pickleball, and go to the beach. Look around my website to learn more!"
  },
  {
    "objectID": "index.html#about-this-website",
    "href": "index.html#about-this-website",
    "title": "Eli Della Bitta",
    "section": "About This Website",
    "text": "About This Website\nThis website showcases my data science projects and analyses. You can find the R code for this website in my GitHub repository."
  },
  {
    "objectID": "index.html#skills-interests",
    "href": "index.html#skills-interests",
    "title": "Eli Della Bitta",
    "section": "Skills & Interests",
    "text": "Skills & Interests\n\nData Analysis: R, data visualization, statistical modeling\nSports: Baseball, golf, pickleball\nHobbies: Beach activities, outdoor recreation"
  },
  {
    "objectID": "presentation.html#the-question",
    "href": "presentation.html#the-question",
    "title": "Police Search Practices Across Three States",
    "section": "The Question",
    "text": "The Question\nDo police search practices look different across states?\nI wanted to find out if some states search drivers more often than others during traffic stops, and whether searching more frequently actually leads to finding more contraband."
  },
  {
    "objectID": "presentation.html#why-look-at-this",
    "href": "presentation.html#why-look-at-this",
    "title": "Police Search Practices Across Three States",
    "section": "Why Look at This?",
    "text": "Why Look at This?\nUnderstanding how police conduct searches matters because:\n\nIt shows us different approaches to law enforcement\nWe can see which strategies are more effective\nIt raises questions about fairness and individual rights\nThe differences between states are pretty significant"
  },
  {
    "objectID": "presentation.html#the-data",
    "href": "presentation.html#the-data",
    "title": "Police Search Practices Across Three States",
    "section": "The Data",
    "text": "The Data\nStanford Open Policing Project\n\nTraffic stop data from California, Texas, and Illinois\nLooking at 2015-2016\nIncludes millions of traffic stops\nTracks both searches and whether contraband was found"
  },
  {
    "objectID": "presentation.html#search-rates-how-often-do-police-search",
    "href": "presentation.html#search-rates-how-often-do-police-search",
    "title": "Police Search Practices Across Three States",
    "section": "Search Rates: How Often Do Police Search?",
    "text": "Search Rates: How Often Do Police Search?"
  },
  {
    "objectID": "presentation.html#what-i-found-search-rates",
    "href": "presentation.html#what-i-found-search-rates",
    "title": "Police Search Practices Across Three States",
    "section": "What I Found: Search Rates",
    "text": "What I Found: Search Rates\nIllinois searches most frequently - around 4.5% of all traffic stops result in a search.\nCalifornia is in the middle at about 3.2% of stops.\nTexas searches much less - only around 1% of stops.\nAll three states show consistent patterns across both years."
  },
  {
    "objectID": "presentation.html#the-follow-up-question",
    "href": "presentation.html#the-follow-up-question",
    "title": "Police Search Practices Across Three States",
    "section": "The Follow-Up Question",
    "text": "The Follow-Up Question\nSo we know Illinois searches most often, Texas searches least often…\nBut which approach actually finds more contraband?\nA “hit rate” tells us what percentage of searches actually found something."
  },
  {
    "objectID": "presentation.html#hit-rates-when-searches-find-contraband",
    "href": "presentation.html#hit-rates-when-searches-find-contraband",
    "title": "Police Search Practices Across Three States",
    "section": "Hit Rates: When Searches Find Contraband",
    "text": "Hit Rates: When Searches Find Contraband"
  },
  {
    "objectID": "presentation.html#the-big-finding",
    "href": "presentation.html#the-big-finding",
    "title": "Police Search Practices Across Three States",
    "section": "The Big Finding",
    "text": "The Big Finding\nThere’s a clear inverse relationship here:\n\nTexas: Searches 1% of stops → Finds contraband 41.7% of the time\nIllinois: Searches 4.5% of stops → Finds contraband 22.4% of the time\nCalifornia: Searches 3.2% of stops → Finds contraband 3.5% of the time\n\nThe state that searches the least (Texas) is actually the most successful per search. The state that searches the most (Illinois) has a lower success rate."
  },
  {
    "objectID": "presentation.html#what-this-actually-means",
    "href": "presentation.html#what-this-actually-means",
    "title": "Police Search Practices Across Three States",
    "section": "What This Actually Means",
    "text": "What This Actually Means\nMore searches doesn’t equal better results.\nIn fact, it seems like the opposite might be true - states that are more selective about when to search tend to be more successful when they do search.\nThis suggests different standards for what justifies a search. Texas appears to have stricter criteria, while Illinois and California may be using broader reasons to initiate searches."
  },
  {
    "objectID": "presentation.html#all-three-states-compared",
    "href": "presentation.html#all-three-states-compared",
    "title": "Police Search Practices Across Three States",
    "section": "All Three States Compared",
    "text": "All Three States Compared\n\n\n\nComplete Comparison (2015-2016)\n\n\nState\nSearch Rate (%)\nTotal Stops\nHit Rate (%)\n\n\n\n\nIllinois\n4.46\n4192128\n22.43\n\n\nCalifornia\n3.20\n5957628\n3.51\n\n\nTexas\n1.57\n3577592\n41.65"
  },
  {
    "objectID": "presentation.html#key-takeaways",
    "href": "presentation.html#key-takeaways",
    "title": "Police Search Practices Across Three States",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nCalifornia stands out for the wrong reasons: While searching 3.2% of stops (more than Texas), California only finds contraband 3.5% of the time - meaning 96.5% of searches turn up nothing.\nTexas searches way less often (1% of stops) but is successful 41.7% of the time - that’s 12 times more effective than California per search.\nIllinois falls in the middle - searches most frequently (4.5%) with moderate success (22.4%).\nThe big question: Why is California’s hit rate so incredibly low? This suggests potential issues with how they’re deciding when to search."
  },
  {
    "objectID": "presentation.html#why-this-matters",
    "href": "presentation.html#why-this-matters",
    "title": "Police Search Practices Across Three States",
    "section": "Why This Matters",
    "text": "Why This Matters\nThese aren’t small differences - they’re huge.\nCalifornia’s 3.5% hit rate means that in nearly 19 out of 20 searches, nothing is found. This raises some questions about the criteria being used.\nThe data suggests there might be better and worse ways to approach searches during traffic stops, with real implications for both effectiveness and individual rights."
  },
  {
    "objectID": "presentation.html#questions",
    "href": "presentation.html#questions",
    "title": "Police Search Practices Across Three States",
    "section": "Questions?",
    "text": "Questions?\nThanks for listening!"
  },
  {
    "objectID": "sql-analysis.html",
    "href": "sql-analysis.html",
    "title": "Eli Della Bitta - Data Science Portfolio",
    "section": "",
    "text": ". jkm— title: “Police Search Practices Across Three States” description: | SQL analysis comparing search rates and contraband recovery in California, Texas, and Illinois traffic stops author: Eli Della Bitta date: December 1, 2025 format: html: warning: false message: false code-fold: true —"
  },
  {
    "objectID": "sql-analysis.html#introduction",
    "href": "sql-analysis.html#introduction",
    "title": "Eli Della Bitta - Data Science Portfolio",
    "section": "Introduction",
    "text": "Introduction\nMy analysis examines traffic stop data from the Stanford Open Policing Project to compare police search practices across three states: California, Texas, and Illinois. I focused on two key questions: How often do police search drivers during traffic stops, and how successful are those searches at finding contraband? Understanding these patterns matters because differences in search practices can show us possible variance in enforcement priorities and raise questions about fairness in policing."
  },
  {
    "objectID": "sql-analysis.html#connecting-to-the-database",
    "href": "sql-analysis.html#connecting-to-the-database",
    "title": "Eli Della Bitta - Data Science Portfolio",
    "section": "Connecting to the Database",
    "text": "Connecting to the Database\n\nlibrary(DBI)\nlibrary(RMariaDB)\n\nWarning: package 'RMariaDB' was built under R version 4.5.2\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.5.2\n\n\nWarning: package 'lubridate' was built under R version 4.5.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\n\ncon_traffic &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"traffic\",\n  host = \"traffic.st47s.com\",\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n)"
  },
  {
    "objectID": "sql-analysis.html#search-rates-analysis",
    "href": "sql-analysis.html#search-rates-analysis",
    "title": "Eli Della Bitta - Data Science Portfolio",
    "section": "Search Rates Analysis",
    "text": "Search Rates Analysis\nTo understand how often police conduct searches during traffic stops, I will retrieve data from all three states for the years 2015-2016.\n\n-- Combine search rate data from three states\n-- For each state and year, calculate total stops, searches, and search rate percentage\n\nSELECT \n  'California' AS state,\n  YEAR(date) AS stop_year,\n  COUNT(*) AS total_stops,\n  SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END) AS searches_conducted,\n  ROUND(100.0 * SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END) / COUNT(*), 2) AS search_rate_percent\nFROM ca_statewide_2023_01_26\nWHERE YEAR(date) BETWEEN 2015 AND 2016\nGROUP BY stop_year\n\nUNION ALL\n\nSELECT \n  'Texas' AS state,\n  YEAR(date) AS stop_year,\n  COUNT(*) AS total_stops,\n  SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END) AS searches_conducted,\n  ROUND(100.0 * SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END) / COUNT(*), 2) AS search_rate_percent\nFROM tx_statewide_2020_04_01\nWHERE YEAR(date) BETWEEN 2015 AND 2016\nGROUP BY stop_year\n\nUNION ALL\n\nSELECT \n  'Illinois' AS state,\n  YEAR(date) AS stop_year,\n  COUNT(*) AS total_stops,\n  SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END) AS searches_conducted,\n  ROUND(100.0 * SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END) / COUNT(*), 2) AS search_rate_percent\nFROM il_statewide_2020_04_01\nWHERE YEAR(date) BETWEEN 2015 AND 2016\nGROUP BY stop_year\n\nORDER BY state, stop_year;\n\n\nVisualization: Search Rates Over Time\n\n# Create line plot showing search rate trends\n# Each state gets its own colored line showing search rates across 2015-2016\nggplot(search_rates, aes(x = stop_year, y = search_rate_percent, color = state, group = state)) +\n  geom_line(linewidth = 1.2) +\n  geom_point(size = 2.5) +\n  labs(\n    title = \"Police Search Rates During Traffic Stops (2015-2016)\",\n    subtitle = \"Comparison across California, Texas, and Illinois\",\n    x = \"Year\",\n    y = \"Search Rate (%)\",\n    color = \"State\"\n  ) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"California\" = \"#1f77b4\", \"Texas\" = \"#ff7f0e\", \"Illinois\" = \"#2ca02c\"))\n\nDon't know how to automatically pick scale for object of type &lt;integer64&gt;.\nDefaulting to continuous.\n\n\n\n\n\n\n\n\n\nWhat I See: The line chart ends up showing us very clear differences in search frequency across the three states. Illinois searches most frequently at around 4.5% of all traffic stops, California falls in the middle at approximately 3.2%, and Texas conducts searches in only about 1% of stops. All three states show stable patterns across both years, suggesting these differences reflect consistent state-level policies rather than year-to-year fluctuations. Illinois officers search drivers roughly 4.5 times more often than Texas officers during traffic stops."
  },
  {
    "objectID": "sql-analysis.html#contraband-recovery-analysis",
    "href": "sql-analysis.html#contraband-recovery-analysis",
    "title": "Eli Della Bitta - Data Science Portfolio",
    "section": "Contraband Recovery Analysis",
    "text": "Contraband Recovery Analysis\nSearch frequency alone doesn’t tell the full story. To further look at effectiveness, I examine “hit rates” - the percentage of searches that actually recover contraband. Higher hit rates indicate more targeted, selective searching, while lower rates suggest searches may be conducted with less concrete justification.\n\n-- Calculate contraband recovery rates (hit rates) for each state\n-- Hit rate = (searches finding contraband / total searches) * 100\n\nSELECT \n  'California' AS state,\n  SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END) AS searches_conducted,\n  SUM(CASE WHEN contraband_found = TRUE THEN 1 ELSE 0 END) AS contraband_found,\n  ROUND(100.0 * SUM(CASE WHEN contraband_found = TRUE THEN 1 ELSE 0 END) / \n    SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END), 2) AS hit_rate_percent\nFROM ca_statewide_2023_01_26\nWHERE YEAR(date) BETWEEN 2015 AND 2016\n\nUNION ALL\n\nSELECT \n  'Texas' AS state,\n  SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END) AS searches_conducted,\n  SUM(CASE WHEN contraband_found = TRUE THEN 1 ELSE 0 END) AS contraband_found,\n  ROUND(100.0 * SUM(CASE WHEN contraband_found = TRUE THEN 1 ELSE 0 END) / \n    SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END), 2) AS hit_rate_percent\nFROM tx_statewide_2020_04_01\nWHERE YEAR(date) BETWEEN 2015 AND 2016\n\nUNION ALL\n\nSELECT \n  'Illinois' AS state,\n  SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END) AS searches_conducted,\n  SUM(CASE WHEN contraband_found = TRUE THEN 1 ELSE 0 END) AS contraband_found,\n  ROUND(100.0 * SUM(CASE WHEN contraband_found = TRUE THEN 1 ELSE 0 END) / \n    SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END), 2) AS hit_rate_percent\nFROM il_statewide_2020_04_01\nWHERE YEAR(date) BETWEEN 2015 AND 2016;\n\n\nVisualization: Contraband Recovery Rates\n\n# Create bar plot showing hit rates\n# Bars ordered from highest to lowest hit rate\nggplot(hit_rates, aes(x = reorder(state, -hit_rate_percent), y = hit_rate_percent, fill = state)) +\n  geom_col(width = 0.6) +\n  geom_text(aes(label = paste0(hit_rate_percent, \"%\")), vjust = -0.5, size = 4) +\n  labs(\n    title = \"Contraband Recovery Rates by State (2015-2016)\",\n    subtitle = \"Percentage of searches that recovered contraband\",\n    x = \"State\",\n    y = \"Hit Rate (%)\",\n    fill = \"State\"\n  ) +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"California\" = \"#1f77b4\", \"Texas\" = \"#ff7f0e\", \"Illinois\" = \"#2ca02c\")) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWhat I See: The bar chart reveals an inverse relationship between search frequency and search success. Texas, which searches least often (1% of stops), has the highest hit rate at 41.65% - meaning contraband is found in over 4 out of 10 searches. Illinois, searching most frequently (4.5% of stops), achieves a moderate 22.43% hit rate. California’s results are particularly noteworthy: despite searching 3.2% of stops, California finds contraband in only 3.51% of searches, meaning 96.5% of California searches turn up nothing. Texas is 12 times more successful per search than California, suggesting different standards for what constitues a search. This could be due to different state laws surrounding drugs and weapons, not only policing policy. ## Summary Comparison\n\n# Combine search rates and hit rates into comprehensive summary table\n# Calculate average search rate across both years for each state\nsummary_data &lt;- search_rates |&gt;\n  group_by(state) |&gt;\n  summarise(\n    avg_search_rate = mean(search_rate_percent),\n    total_stops = sum(total_stops)\n  ) |&gt;\n  left_join(hit_rates |&gt; select(state, hit_rate_percent), by = \"state\") |&gt;\n  arrange(desc(avg_search_rate))\n\nknitr::kable(summary_data, \n             digits = 2,\n             col.names = c(\"State\", \"Avg Search Rate (%)\", \"Total Stops (2015-2016)\", \"Hit Rate (%)\"),\n             caption = \"Summary Statistics: Search Patterns Across Three States\")\n\n\nSummary Statistics: Search Patterns Across Three States\n\n\n\n\n\n\n\n\nState\nAvg Search Rate (%)\nTotal Stops (2015-2016)\nHit Rate (%)\n\n\n\n\nIllinois\n4.46\n4192128\n22.43\n\n\nCalifornia\n3.20\n5957628\n3.51\n\n\nTexas\n1.57\n3577592\n41.65\n\n\n\n\n\nWhat I See: The table highlights the variation in police search practices. Illinois conducts searches at the highest rate (4.47%) but with a moderate hit rate (22.43%). California searches at an intermediate rate (3.20%) but has an extremely low hit rate (3.51%), meaning nearly 19 out of 20 California searches find nothing. Texas takes a very selective approach, searching only 1.05% of stops but achieving a 41.65% hit rate. The total stops column shows all three states have substantial sample sizes, with California conducting the most traffic stops overall (nearly 6 million), followed by Illinois (4.2 million) and Texas (3.6 million)."
  },
  {
    "objectID": "sql-analysis.html#conclusion",
    "href": "sql-analysis.html#conclusion",
    "title": "Eli Della Bitta - Data Science Portfolio",
    "section": "Conclusion",
    "text": "Conclusion\nThis SQL analysis examined traffic stop and search patterns across California, Texas, and Illinois using 2015-2016 data from the Stanford Open Policing Project. The data reveals significant differences in how frequently police conduct searches during traffic stops, with Illinois searching drivers at approximately 4.5 times the rate of Texas. However, higher search rates do not correspond to higher contraband recovery rates. In fact, the relationship is inverse: Texas, which searches least frequently, finds contraband in over 40% of searches, while California, with a moderate search rate, finds contraband in only 3.5% of searches.\nCalifornia’s extremeley low hit rate could be problematic. When 96.5% of searches yield no contraband, it raises some questions about whether the criteria being used to conduct searches are appropriate. These findings suggest that state-level policies and police department practices significantly impact both search frequency and effectiveness. Understanding this is important for how we view personal liberties in our country."
  },
  {
    "objectID": "sql-analysis.html#sql-keywords-used",
    "href": "sql-analysis.html#sql-keywords-used",
    "title": "Eli Della Bitta - Data Science Portfolio",
    "section": "SQL Keywords Used",
    "text": "SQL Keywords Used\nThroughout this analysis, I used the following SQL keywords beyond SELECT, FROM, and LIMIT:\n\nWHERE - Filtered data to years 2015-2016 and specific search conditions\nGROUP BY - Separated data by year and state for aggregation\nCOUNT - Counted total stops\nSUM - Summed searches conducted and contraband found\nCASE WHEN - Created conditional logic for calculating rates\nUNION ALL - Combined results from three state tables\nORDER BY - Sorted results by state and year\nYEAR() - Extracted year from date fields\nROUND - Rounded percentages to two decimal places"
  },
  {
    "objectID": "sql-analysis.html#data-source",
    "href": "sql-analysis.html#data-source",
    "title": "Eli Della Bitta - Data Science Portfolio",
    "section": "Data Source",
    "text": "Data Source\nPrimary Citation: Pierson, E., Simoiu, C., Overgoor, J., Corbett-Davies, S., Jenson, D., Shoemaker, A., Ramachandran, V., Shroff, R., & Goel, S. (2020). A large-scale analysis of racial disparities in police stops across the United States. Nature Human Behaviour, 4(7), 736-745. https://doi.org/10.1038/s41562-020-0858-1\nData Source: Stanford Open Policing Project. https://openpolicing.stanford.edu/\nThe Stanford Open Policing Project collected and standardized police stop data from law enforcement agencies across the United States, providing one of the most comprehensive datasets on traffic stops and police-civilian interactions. The data includes information on over 200 million traffic stops from state patrol agencies and municipal police departments.\n\n# Disconnect from database to free up resources\ndbDisconnect(con_traffic)"
  }
]